\section{2d exploration strategies}

Exploration algorithms can be grouped into centralized and decentralized. In the  centralized approach, each mobile robot receives tasks from a single central \emph{leader} which runs the overall planning algorithm, and afterwards the mobile robot sends its info back to the leader. Centralized assignment may be less practical due to communication limits (\cite{Dias2000}), robustness issues (\cite{Dias2006}), or time required for algorithm execution and scalability (\cite{Julia2012}). An advantage of centralized approach is that optimal plans can be found (\cite{Yan2011}). 

In contrast to centralized approaches, in a decentralized approach, the mobile robots are completely independent throughout the exploration process. Each mobile robot has its own local knowledge of the world and can decide its future actions by taking into account its current context and tasks, its own capacities and the capacities of the other mobile robots, through a negotiation process (\cite{Yan2013}). Moreover, it typically has better reliability, flexibility, adaptability and robustness (\cite{Zlot2002}). 
 
There are several representative approaches from the both centralized and decentralized groups described in the following text. 



\subsection{Nearest Frontier Approach} 

An unexplored area is usually represented using an occupancy grid map introduced by \cite{Moravec}. While a robot moves, an occupancy likelihood for each cell of the grid is updated with the information of sensors. Depending on this occupancy likelihood, cells can be classified as free, occupied or unknown. Using an occupancy grid a mobile robot can reach an unexplored zone navigating to the frontier cells that separate the free cells from the unknown cells known as \textit{frontiers} \cite{Yamauchi1997}. Yamauchi's technique consists in selecting the shortest path to the nearest frontier. In this way, the target cell selected by this technique $t_{NF}$ is:

\begin{equation}
t_{NF} = \argmin_{a \in F} L(a), 
\label{equation:t-nf}
\end{equation}

where $L(a)$ represents the length of the shortest path to reach the cell $a$ ($a_{i}$, $a_{j}$) and $F$ the subset of the frontier cells \cite{Julia2012}. As it can be noticed, (\ref{equation:t-nf}) only takes into account the cost of reaching a frontier cell and does not provide any coordination mechanism. In case a single mobile robot system is extended to a multi-robot system, mobile robots may select the same frontier if they are situated in nearby positions. For instance, \cite{Yamauchi1998} extended his nearest frontier approach to multiple mobile robots using global maps built by each robot with the information provided by all robots. Since mobile robots share the acquired information, exploration is cooperative, but mobile robot movements are uncoordinated. When the robots are in close positions it is likely that they choose the same frontier to explore if no other coordination mechanisms are considered.

Frontier exploration strategies are also extended to a multi-robot system in \cite{Simmons2000} and \cite{Burgard2005}. Simmons \cite{Simmons2000} used a semi-distributed model where a centralized module integrated local data from a team of mobile robots. The team used a probabilistic technique to build a global map in a coordinated fashion. Due to the problem of absolute positioning techniques in indoor environments, robots must estimate their local pose in an environment, leading to odometry errors. Simmons used probability calculations to estimate the local pose of each robot, and built a global map by joining each individual robots local map. 
While Simmons \cite{Simmons2000} implements coordination between robots by sharing of map information and reducing the utility of frontier points in the vicinity of an allotted point, Burgard \cite{Burgard2005} came up with an elegant bidding process. 

A dense frontier points detection method implemented by Orsulic (\cite{Orsulic2019}) is an extension to Google Cartographer (\cite{Hess2016}) that has achieved good results in terms of wall-time per frontier update, which greatly speeds up exploration process. Orsulic used nearest frontier approach in order to explore an area. 

Rekeleitis \cite{Rekeleitis2000} covered terrains with multiple robots where at least one robot was stationary and posed as an observer. In \cite{Fox2006} a decision theoretic approach to multi-robot exploration was presented where the main problem was to decide whether a mobile robot should explore the terrain or to verify the hypothesis of other robots whose states are not mapped into a common reference frame. The nearest unexplored region technique is also used by Wullschleger \cite{Wullschleger99}, Santosh \cite{Santosh2008}, Murphy and Newman \cite{Murphy2008}, to name a few more.


\subsection{Cost-Utility Approach}

Generally, in a cost-utility approach a goal point maximizes the benefit between cost and utility. The utility is measured in terms of the expectation of the information incorporated to the occupancy map from the position of the goal point. An example of cost-utility approach was presented by González-Baños and Latombe \cite{GonzlezBaos2002}. Frontier cells are designated as candidate destinations and the benefit $B_{CU}(a)$ to reach a candidate cell a is evaluated according to the following expression \cite{Julia2012}:
\begin{equation}
B_{CU}(a) = U(a) - \lambda_{CU}C(a),
\end{equation}

where $U(a)$ is a utility function, $C(a)$ is a cost function and $\lambda$ is a constant that adjusts the relative importance between both factors. Utility and cost functions are expressions normalized in the range $\left[0, 1\right]$ that are calculated as follows:
\begin{equation}
U(a) = \frac{U_{nex}(a, R_{s})}{\pi R_{s}^{2}},
\end{equation}
\begin{equation}
C(a) = \frac{L(a)}{max_{b \in F}L(b)},
\end{equation}

where the function $U_{nex}(a. R_{s})$ is the result of counting the number of unexplored cells in the range of the sensor from cell $d$, being $R_{s}$ the maximum range of the sensor expressed in cell units.
Then, the target cell $t_{CU}$ is chosen as the one that maximizes the utility-cost relation:

\begin{equation}
t_{CU} = \argmax_{a \in F} B_{CU}(a).
\end{equation}

Similar to the work proposed by Simmons, Burgard \cite{Burgard2000} introduced some coordination by means of reducing a determined initial utility given to each frontier depending on the likelihood of being in the sensor range from other frontiers that have been assigned to other robots. The assignment of frontiers to robots is made sequentially using a cost-utility approach with the length of the minimum path as cost. It is assumed that robots know each others relative positions. The algorithm determines optimal target points for each robot that increase the coverage by the maximum amount at that time period. Moreover, Burgard in \cite{Burgard2005} suggested that the assignment of frontiers to robots could be optimized using the Hungarian method \cite{Kuhn1955} instead of the sequential assignment.

Another example of cost-utility model is given in \cite{Umari2017}, where a frontier detection method is based on Rapidly Exploring Random Trees (RRTs). Umari defined revenue from a frontier point as a combination of an information gain and navigation cost. 


\subsection{Market-Based Coordinated}

%Relatively close to Burgard‟s approach in Collaborative Multi-Robot Exploration, Zlot [27] uses
%the concept of frontier cells and utility in a market environment to produce complex coordinated
%behavior between multi-robots for exploration. In this approach, exploration is performed by
%visiting goal points (referred to as target points in Burgard‟s work) in unexplored regions. A
%robot contains a task list called a tour which contains several goal points. Tours are refined
%through robot negotiation in the market, and allows the robots to improve their exploration in an
%efficient manner. Each robot has a market agent called the operator executive, or OpExec, which
%is responsible for processing bids, handling revenue, and so forth. The revenue function is
%similar to Burgard‟s, where P = R – C.
%Tasks are the primary commodity handled in the market. By definition, a task is a singular goal
%point to visit, thus a key component of the system is the methodology by which goal points are
%selected. Four different strategies are analyzed: random, greedy, quadtree division, and no
%communication. In the random strategy, goal points are selected by a random process, but any
%goal points are discarded if the area surrounding the goal point has been visited. The greedy
%process chooses the goal point in the closest unexplored region to the robot. The quadtree
%strategy transforms the space into a quadtree representation, and the largest unknown leaf regions
%are selected as candidates for exploration, with goal points located at the center of the leaf. The
%no communication scenario emulates robots with no coordination available. In this case, robots
%used the random goal generation strategy without any information sharing.
%Robots negotiate using single-item first-price sealed-bid auctions, and may auction any of their
%tasks in their current tour. The robots internal valuation of the task is the profit expected if the
%task was added to the robots existing tour, and the auctioneer then announces a reservation price
%Pr, where Pr is the robots valuation plus a small fixed amount. Bidding strategies for robots are
%defined by the formula: 
%Where a is between 0 and 1, with higher coefficients resulting in an increased incentive to sell
%the item, while at the same time the buyer gets a large fraction of their valuation if they win.
%This enables the robot to effectively sell an item to the robot that can perform the task most
%efficiently.
%The system is responsive to robot loss due to the nature of the goal generation strategy. If a robot
%fails while completing a tour, existing robots will eventually generate goal points in those areas,
%thereby negating the loss of that robot. In addition, map sharing is done at explicit intervals (and
%can be manually performed by a human operator), where a robot periodically sends out a small
%explored section of its own map on a peer-to-peer basis with robots in communication range. The
%maps are composed in a simplistic manner whereas [3] uses a probabilistic mechanism to
%combine occupancy maps. Experimental results indicate that the market based economy
%functions much better than a non-coordinated approach. Both random and quadtree goal point
%selection strategies have an area covered to distance traveled ratio of greater than 1, while the no
%communication strategy ratio is significantly less than 1, meaning that robots are covering less
%area than they are traveling.
